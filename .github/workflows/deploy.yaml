name: Test and Deploy ETL Pipeline

on:
  push:
    branches:
      - master

jobs:
  #test:
  #  runs-on: ubuntu-latest

  #  steps:
  #    - name: Checkout code
  #      uses: actions/checkout@v2

      #- name: Set up Python
      #  uses: actions/setup-python@v2
      #  with:
      #    python-version: '3.8'

      #- name: Install dependencies
      #  run: |
      #    pip install -r requirements.txt
      #    pip install pytest

      #- name: Run Tests
      #  run: pytest test_etl.py

  deploy:
    runs-on: ubuntu-latest
    #needs: test

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.0.0
 
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: Zip common_utils.py
        run: zip -r common_utils.zip etl_script/common_utils.py

      - name: Upload scripts and dependencies to S3
        run: |
          aws s3 cp etl_script/01_bronze.py s3://sales-pyspark-etl/etl_script/01_bronze.py
          aws s3 cp etl_script/02_silver.py s3://sales-pyspark-etl/etl_script/02_silver.py
          aws s3 cp common_utils.zip s3://sales-pyspark-etl/etl_script/common_utils.zip

      - name: Initialize Terraform
        working-directory: ./terraform
        run: terraform init

      - name: Apply Terraform
        working-directory: ./terraform
        env:
          TF_VAR_bronze_script_location: "s3://sales-pyspark-etl/etl_script/01_bronze.py"
          TF_VAR_silver_script_location: "s3://sales-pyspark-etl/etl_script/02_silver.py"
          TF_VAR_common_utils_location: "s3://sales-pyspark-etl/etl_script/common_utils.zip"
        run: terraform apply -auto-approve -input=false
